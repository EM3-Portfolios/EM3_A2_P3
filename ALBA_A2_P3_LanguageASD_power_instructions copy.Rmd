---
title: "Assignment 1 - Language Development in ASD - Power and simulations"
author: "Alba, Manon, Cecilie, LÃ¦rke Bradder"
date: "30-09-2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Welcome to the third exciting part of the Language Development in ASD exercise

In this part of the assignment, we try to figure out how a new study should be planned (i.e. how many participants?) in order to have enough power to replicate the findings (ensuring our sample size is adequate, our alpha at 0.05 and our beta at 0.8):
1- if we trust the estimates of the current study. Report the power analysis and comment on what you can (or cannot) use its estimates for.
2- if we are skeptical of the current study. Report the power analysis and comment on what you can (or cannot) use its estimates for.
3- if we only have access to 30 participants. Identify the power for each relevant effect and discuss whether it's worth to run the study and why
The list above is also what you should discuss in your code-less report.


## Learning objectives

- Learn how to calculate statistical power
- Critically appraise how to apply frequentist statistical power

### Exercise 1

How much power does your study have (if your model estimates are quite right)?
- Load your dataset (both training and testing), fit your favorite model, assess power for your effects of interest (probably your interactions).
- Report the power analysis and comment on what you can (or cannot) use its estimates for.
- Test how many participants you would have to have to replicate the findings (assuming the findings are correct)

N.B. Remember that main effects are tricky once you have interactions in the model (same for 2-way interactions w 3-way interactions in the model). If you want to test the power of main effects, run a model excluding the interactions.
N.B. Check this paper: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504
You will be using:
- powerSim() to calculate power
- powerCurve() to estimate the needed number of participants
- extend() to simulate more participants

```{r}
#Load packages
pacman::p_load(lmerTest, simr, lme4)

#Load dataframes
df_train <- read.csv("/Users/al/RStudio/Semester 3/Experimental-Methods-3/Assignment 2/EM3_A2_P3/data_clean.csv")
df_test <- read.csv("/Users/al/RStudio/Semester 3/Experimental-Methods-3/Assignment 2/EM3_A2_P3/cleantestdf.csv")

#Deleting NAs from the columns/variables that we are interested in
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}

df_train <- completeFun(df_train, "CHI_MLU")
df_test <- completeFun(df_test, "CHI_MLU")

#Removing some columns from the train dataframe to be able to bind it with the test data
df_train$MOT_LUstd <- NULL
df_train$CHI_LUstd <- NULL

#replacing the names in df_train so the names do not overlap
df_test$Child.ID <- replace(df_test$Child.ID, 6:12, "67")
df_test$Child.ID <- replace(df_test$Child.ID, 12:18, "68")
df_test$Child.ID <- replace(df_test$Child.ID, 18:24, "69")
df_test$Child.ID <- replace(df_test$Child.ID, 24:30, "70")
df_test$Child.ID <- replace(df_test$Child.ID, 30:35, "71")

#Creating 1 dataset made of both test and train data
df <- rbind(df_train, df_test)

#making it be in order
df$Child.ID <- as.factor(df$Child.ID)
df$Child.ID <- as.numeric(df$Child.ID)
df$Child.ID <- as.character(df$Child.ID)
df$Child.ID <- as.factor(df$Child.ID)

#Applying function CompleteFun to binded/merged df
#df <- completeFun(df, "CHI_MLU")
```


```{r}

#Loading the decided model
m <- lmer(CHI_MLU ~ Diagnosis * Visit + (1 + Visit + I(Visit^2) | Child.ID), df, REML=FALSE, lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

#Assessing power for our effects of interest
powerV <- powerSim(m, fixed("Diagnosis:Visit"), nsim = 50)
#fixef(m)["Diagnosis:Visit"] <- 10
powerCurveV <- powerCurve(m, fixed("Diagnosis:Visit"), along = "Child.ID", nsim = 50)
powerV
plot(powerCurveV)
print(powerCurveV)

#Extend function applied to add more simulated datapooints for new children
m2 <- extend(m, along = "Child.ID", n = 100)

#Apply Power curve
powerV2 <- powerSim(m2, fixed("Diagnosis:Visit"), nsim = 50)
powerCurveV2 <- powerCurve(m2, fixed("Diagnosis:Visit"), along = "Child.ID", nsim = 50)
powerV2
plot(powerCurveV2)
print(powerCurveV2)


```


### Exercise 2

How would you perform a more conservative power analysis?
- Identify and justify a minimum effect size for each of your relevant effects
- take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.
- assess the power curve by Child.ID, identifying an ideal number of participants to estimate each effect
- if your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis
- Report the power analysis and comment on what you can (or cannot) use its estimates for.


```{r Exercise 2.1 - Identify and justify a minimum effect size for each of your relevant effects}
#We're deciding to set the effect size 
fixef()

```

```{r Exercise 2.2 - Take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.}

```

```{r Exercise 2.3 - Assess the power curve by Child.ID identifying an ideal number of participants to estimate each effect}

```

```{r Exercise 2.4 - If your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis}

```

```{r Exercise 2.5 - Report the power analysis and comment on what you can (or cannot) use its estimates for.}

```


### Exercise 3

Assume you have only the resources to collect 30 kids (15 with ASD and 15 TDs). Identify the power for each relevant effect and discuss whether it's worth to run the study and why

```{r}
# Recreating our model to the new data-subset:
m3 <- lme4::lmer(CHI_MLU ~ Diagnosis * Visit + (1 + Visit + I(Visit^2) | Child.ID), df3, REML = FALSE, lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
```

```{r}
powerDV3 <- powerSim(m3, fixed("Diagnosis:Visit"), nsim = 50)
powerCurveDV3 <- simr::powerCurve(m3, test = fixed("Diagnosis:Visit"), along = "Child.ID", nsim = 50)

powerDV3
plot(powerCurveDV3)
print(powerCurveDV3)

#The power is 82% for n=31, but we only have resources to collect data from 30 kids. The confidence interval goes from 68.56 to 91.42. Since we can't be sure that this study would be powered properly, we should have more data. However, our resources are limited to 30 children. How could we solve this dilemma? How can we be sure that the study is not underprowered but without having to use another 
```


