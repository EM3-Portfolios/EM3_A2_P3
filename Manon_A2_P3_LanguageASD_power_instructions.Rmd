---
title: "Assignment 1 - Language Development in ASD - Power and simulations"
author: "Manon Grandjean"
date: "[DATE]"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(readr, dplyr, simr, lme4)
```

## Welcome to the third exciting part of the Language Development in ASD exercise

In this part of the assignment, we try to figure out how a new study should be planned (i.e. how many participants?) in order to have enough power to replicate the findings (ensuring our sample size is adequate, our alpha at 0.05 and our beta at 0.8)
1- if we trust the estimates of the current study. Report the power analysis and comment on what you can (or cannot) use its estimates for.
2- if we are skeptical of the current study. Report the power analysis and comment on what you can (or cannot) use its estimates for.
3- if we only have access to 30 participants. Identify the power for each relevant effect and discuss whether it's worth to run the study and why
The list above is also what you should discuss in your code-less report.

## Learning objectives

- Learn how to calculate statistical power
- Critically appraise how to apply frequentist statistical power



### Exercise 1

How much power does your study have (if your model estimates are quite right)?
- Load your dataset (both training and testing), fit your favorite model, assess power for your effects of interest (probably your interactions).
- Report the power analysis and comment on what you can (or cannot) use its estimates for.
- Test how many participants you would have to have to replicate the findings (assuming the findings are correct)

N.B. Remember that main effects are tricky once you have interactions in the model (same for 2-way interactions w 3-way interactions in the model). If you want to test the power of main effects, run a model excluding the interactions.
N.B. Check this paper: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12504
You will be using:
- powerSim() to calculate power
- powerCurve() to estimate the needed number of participants
- extend() to simulate more participants

```{r Exercise 1.1 - Loading the data and fitting our favorite model}
df_train <- read_csv("data_clean.csv")
df_test <- read_csv("cleantestdf.csv")

# Cleaning function to remove NAs for relevasnt varibales - 352
completeFun <- function(data, desiredCols) {
  completeVec <- complete.cases(data[, desiredCols])
  return(data[completeVec, ])
}
df_train <- completeFun(df_train, "CHI_MLU")

# Fitting our favorite model
m <- lmer(CHI_MLU ~ Diagnosis * Visit + (1 + Visit + I(Visit^2) | Child.ID), data = df_train, REML = FALSE, lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))

summary(m)

# and how was it again that we should interpret the estimates of the fixed effetcs when there is an interaction?
```

```{r Exercise 1.1 & 1.2 - Assessing power for effects}
powerDV <- powerSim(m, fixed("Diagnosis:Visit"), nsim = 10)
powerCurveDV <- powerCurve(m, fixed("Diagnosis:Visit"), along = "Child.ID", nsim = 10)
powerDV
plot(powerCurveDV)
print(powerCurveDV)

# So if (when nsim=50) the first time the dot and the bars are over 80% is around 25 participants, does this mean that we would only need 25 participants before the interaction had sufficient power?
```
```{r Exercise 1.3 - Using the extend() function to test how many participants we would need to replicate the results}
# when nsim=10 as opposed to 50 it does look more like we need more info in order to properly estimate power. (in the above chunk)
m2 <- extend(m, along = "Child.ID", n = 100)

pDV2 <- powerSim(m2, fixed("Diagnosis:Visit"), nsim = 50)
pcDV2 <- powerCurve(m2, fixed("Diagnosis:Visit"), along = "Child.ID", nsim = 50)
pDV2
plot(pcDV2)

# identifying the minimum sample size required (see: simR article)
print(pcDV2)
# It seems, when n= and nsim= are increased, that only around 20 participants would be needed for the power of the interaction to be 80%
# Perhaps even less than 20. we actually don't even need to extend(m) because we already have 66 participants, which is enough to
# use the print(powerCurveDV) function to identify that after 25 participants (25 values of Child.ID) neither the power nor the confidence
# interval is changing any more.


# increasing the n= in extend() doesn't seem to make power estimations more precise, but just gives us a longer x axis to work with so to speak
# increasion the nsim= in powerSim() and powerCurve however does.
# These functions will be useful together if: like with the powerCurveD we would see we may need up to 70 or 80 children to see anything.
```



### Exercise 2

How would you perform a more conservative power analysis?
- Identify and justify a minimum effect size for each of your relevant effects
- take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.
- assess the power curve by Child.ID, identifying an ideal number of participants to estimate each effect
- if your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis
- Report the power analysis and comment on what you can (or cannot) use its estimates for.

```{r Exerciese 2.1 - Identify and justify a minimum effect size for each of your relevant effects}

```

```{r Exercise 2.2 - Take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept.}

```

```{r Exercise 2.3 - Assess the power curve by Child.ID identifying an ideal number of participants to estimate each effect}

```

```{r Exercise 2.4 - If your power estimates do not reach an acceptable threshold simulate additional participants and repeat the previous analysis}

```

```{r Exercise 2.5 - Report the power analysis and comment on what you can (or cannot) use its estimates for.}

```



### Exercise 3

Assume you have only the resources to collect 30 kids (15 with ASD and 15 TDs). Identify the power for each relevant effect and discuss whether it's worth to run the study and why

```{r Exercise 3.1 - Identify power if we could only study 30 participants (observations and participants / stimli balance?)}

```
